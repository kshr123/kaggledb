#!/usr/bin/env python3
"""
ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è©³ç´°å–å¾—ï¼‹è¦ç´„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æŒ‡å®šã—ãŸã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—ã—ã€
LLMã§è¦ç´„ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚
"""

import sys
import os

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '02_backend'))

import sqlite3
from datetime import datetime
from app.config import DATABASE_PATH
from app.services.scraper_service import get_scraper_service
from app.services.llm_service import get_llm_service


def summarize_discussion_for_competition(comp_id: str, max_discussions: int = 10):
    """
    ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—ãƒ»è¦ç´„ã—ã¦DBã«ä¿å­˜
    
    Args:
        comp_id: ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ID
        max_discussions: è¦ç´„ã™ã‚‹æœ€å¤§ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³æ•°
    """
    print(f"\n{'='*60}")
    print(f"ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è¦ç´„: {comp_id}")
    print(f"{'='*60}\n")

    # ã‚µãƒ¼ãƒ“ã‚¹å–å¾—
    scraper = get_scraper_service()
    llm = get_llm_service()

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    # è¦ç´„ãŒã¾ã ãªã„ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼ˆæŠ•ç¥¨æ•°é †ï¼‰
    cursor.execute("""
        SELECT id, title, url, vote_count
        FROM discussions
        WHERE competition_id = ?
          AND (summary IS NULL OR summary = '')
          AND is_pinned = 0
        ORDER BY vote_count DESC
        LIMIT ?
    """, (comp_id, max_discussions))

    discussions = cursor.fetchall()

    if not discussions:
        print(f"âœ“ è¦ç´„å¯¾è±¡ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
        conn.close()
        return

    print(f"ğŸ“‹ {len(discussions)}ä»¶ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚’è¦ç´„ã—ã¾ã™\n")

    # å„ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚’å‡¦ç†
    summarized_count = 0
    skipped_count = 0

    for idx, disc in enumerate(discussions, 1):
        disc_id = disc['id']
        title = disc['title']
        url = disc['url']
        vote_count = disc['vote_count']

        print(f"[{idx}/{len(discussions)}] {title[:60]}... (ğŸ‘ {vote_count})")

        # ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’å–å¾—
        detail = scraper.get_discussion_detail(url, force_refresh=False)

        if not detail or not detail.get('content'):
            print(f"  âš ï¸  å†…å®¹å–å¾—å¤±æ•— - ã‚¹ã‚­ãƒƒãƒ—")
            skipped_count += 1
            continue

        content = detail['content']
        print(f"  âœ“ å†…å®¹å–å¾—å®Œäº† ({len(content)}æ–‡å­—)")

        # LLMã§è¦ç´„
        print(f"  ğŸ¤– LLMè¦ç´„ä¸­...")
        summary = llm.summarize_discussion(content=content, title=title)

        if not summary:
            print(f"  âš ï¸  è¦ç´„ç”Ÿæˆå¤±æ•— - ã‚¹ã‚­ãƒƒãƒ—")
            skipped_count += 1
            continue

        print(f"  âœ“ è¦ç´„å®Œäº†: {summary[:80]}...")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        now = datetime.now().isoformat()
        cursor.execute("""
            UPDATE discussions
            SET content = ?,
                summary = ?,
                updated_at = ?
            WHERE id = ?
        """, (content, summary, now, disc_id))

        conn.commit()
        summarized_count += 1
        print(f"  ğŸ’¾ ä¿å­˜å®Œäº†\n")

    conn.close()

    print(f"{'='*60}")
    print(f"âœ… å®Œäº†: {summarized_count}ä»¶è¦ç´„ã€{skipped_count}ä»¶ã‚¹ã‚­ãƒƒãƒ—")
    print(f"{'='*60}\n")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description='ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è¦ç´„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('competition_id', help='ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³IDï¼ˆä¾‹: titanicï¼‰')
    parser.add_argument('--max', type=int, default=10, help='è¦ç´„ã™ã‚‹æœ€å¤§ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰')

    args = parser.parse_args()

    summarize_discussion_for_competition(
        comp_id=args.competition_id,
        max_discussions=args.max
    )


if __name__ == "__main__":
    main()
