#!/usr/bin/env python3
"""
ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æƒ…å ±å……å®ŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¢å­˜ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼š
1. Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰
2. LLMã‚’ä½¿ç”¨ã—ã¦ä»¥ä¸‹ã‚’ç”Ÿæˆãƒ»æ›´æ–°ï¼š
   - æ—¥æœ¬èªè¦ç´„ (summary)
   - ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— (data_types)
   - ã‚¿ã‚° (tags)
   - ãƒ‰ãƒ¡ã‚¤ãƒ³ (domain)
"""

import sys
import os

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '02_backend'))

import sqlite3
import json
from datetime import datetime
from typing import List, Dict

from app.config import DATABASE_PATH
from app.services.llm_service import get_llm_service
from app.services.scraper_service import get_scraper_service


def get_available_tags() -> Dict[str, List[str]]:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¿ã‚°ãƒã‚¹ã‚¿ã‚’å–å¾—

    Returns:
        ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ã‚¿ã‚°ãƒªã‚¹ãƒˆ
    """
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()

    cursor.execute("SELECT name, category FROM tags ORDER BY category, display_order")
    rows = cursor.fetchall()

    tags_by_category = {}
    for name, category in rows:
        if category not in tags_by_category:
            tags_by_category[category] = []
        tags_by_category[category].append(name)

    conn.close()
    return tags_by_category


def get_competitions_to_enrich(limit: int = None) -> List[Dict]:
    """
    å……å®ŸåŒ–ãŒå¿…è¦ãªã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚’å–å¾—

    Args:
        limit: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶ï¼‰

    Returns:
        ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    # summary, tags, metric_description, ã¾ãŸã¯ dataset_info ãŒç©ºã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚’å–å¾—
    query = """
        SELECT
            id, title, url, start_date, end_date, status,
            metric, metric_description, description, summary, tags, data_types, domain, dataset_info
        FROM competitions
        WHERE (
            summary IS NULL OR summary = ''
            OR tags IS NULL OR tags = '[]' OR tags = ''
            OR metric_description IS NULL OR metric_description = ''
            OR dataset_info IS NULL OR dataset_info = ''
        )
        AND description IS NOT NULL
        AND description != ''
        ORDER BY created_at DESC
    """

    if limit:
        query += f" LIMIT {limit}"

    cursor.execute(query)
    rows = cursor.fetchall()

    competitions = []
    for row in rows:
        comp = dict(row)
        # JSONæ–‡å­—åˆ—ã‚’Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        if comp.get("tags"):
            try:
                comp["tags"] = json.loads(comp["tags"])
            except:
                comp["tags"] = []
        else:
            comp["tags"] = []

        if comp.get("data_types"):
            try:
                comp["data_types"] = json.loads(comp["data_types"])
            except:
                comp["data_types"] = []
        else:
            comp["data_types"] = []

        competitions.append(comp)

    conn.close()
    return competitions


def update_competition(competition: Dict) -> bool:
    """
    ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ›´æ–°

    Args:
        competition: æ›´æ–°ã™ã‚‹ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æƒ…å ±

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()

    try:
        # JSONé…åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        tags_json = json.dumps(competition.get("tags", []), ensure_ascii=False)
        data_types_json = json.dumps(competition.get("data_types", []), ensure_ascii=False)

        now = datetime.now().isoformat()

        cursor.execute("""
            UPDATE competitions
            SET
                summary = ?,
                tags = ?,
                data_types = ?,
                domain = ?,
                metric = ?,
                metric_description = ?,
                dataset_info = ?,
                last_scraped_at = ?,
                updated_at = ?
            WHERE id = ?
        """, (
            competition.get("summary", ""),
            tags_json,
            data_types_json,
            competition.get("domain", ""),
            competition.get("metric", ""),
            competition.get("metric_description", ""),
            competition.get("dataset_info"),  # JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
            competition.get("last_scraped_at"),  # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ—¥æ™‚
            now,
            competition["id"]
        ))

        conn.commit()
        conn.close()
        return True

    except Exception as e:
        print(f"âŒ æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        conn.close()
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description="ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’LLMã§å……å®ŸåŒ–")
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="å‡¦ç†ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆçœç•¥æ™‚ã¯å…¨ä»¶ï¼‰"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="å®Ÿéš›ã«ã¯æ›´æ–°ã›ãšã€å‡¦ç†å†…å®¹ã®ã¿è¡¨ç¤º"
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æƒ…å ±å……å®ŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)

    # LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    try:
        llm_service = get_llm_service()
        print("âœ… LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ LLMã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}")
        print("ğŸ’¡ OPENAI_API_KEY ãŒ .env ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        return

    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    try:
        scraper_service = get_scraper_service()
        print("âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å¤±æ•—: {e}")
        return

    # ã‚¿ã‚°ãƒã‚¹ã‚¿å–å¾—
    available_tags = get_available_tags()
    print(f"âœ… ã‚¿ã‚°ãƒã‚¹ã‚¿å–å¾—: {sum(len(tags) for tags in available_tags.values())}ä»¶")

    # å……å®ŸåŒ–å¯¾è±¡ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³å–å¾—
    competitions = get_competitions_to_enrich(limit=args.limit)
    if not competitions:
        print("âœ… å……å®ŸåŒ–ãŒå¿…è¦ãªã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“")
        return

    print(f"ğŸ“Š å……å®ŸåŒ–å¯¾è±¡: {len(competitions)}ä»¶")
    print("-" * 60)

    # å„ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†
    success_count = 0
    error_count = 0

    for i, comp in enumerate(competitions, 1):
        print(f"\n[{i}/{len(competitions)}] {comp['title']}")
        print(f"  ID: {comp['id']}")

        try:
            # 1. Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§è©³ç´°æƒ…å ±ã‚’å–å¾—
            scraped_data = scraper_service.get_competition_details(comp['id'])

            if scraped_data and scraped_data.get('full_text'):
                print(f"  ğŸŒ Overview ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°: {len(scraped_data['full_text'])}æ–‡å­—å–å¾—")
                # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸè©³ç´°ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                comp['description'] = scraped_data['full_text']
                comp['last_scraped_at'] = scraped_data['scraped_at']
            else:
                print(f"  âš ï¸  ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•— - API ã® description ã‚’ä½¿ç”¨")
                comp['last_scraped_at'] = None

            # 2. Dataã‚¿ãƒ–ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆdataset_infoãŒç©ºã®å ´åˆã®ã¿ï¼‰
            data_tab_text = None
            if not comp.get('dataset_info'):
                data_tab_data = scraper_service.get_tab_content(comp['id'], tab='data')
                if data_tab_data and data_tab_data.get('full_text'):
                    data_tab_text = data_tab_data['full_text']
                    print(f"  ğŸŒ Data ã‚¿ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°: {len(data_tab_text)}æ–‡å­—å–å¾—")
                else:
                    print(f"  âš ï¸  Data ã‚¿ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—")

            # 3. LLMã§å……å®ŸåŒ–
            enriched = llm_service.enrich_competition(comp, available_tags, data_tab_text=data_tab_text)

            # çµæœã‚’è¡¨ç¤º
            if enriched.get("summary"):
                print(f"  âœ… è¦ç´„ç”Ÿæˆ: {len(enriched['summary'])}æ–‡å­—")
            if enriched.get("metric"):
                metric_text = enriched['metric']
                if enriched.get("metric_description"):
                    print(f"  âœ… è©•ä¾¡æŒ‡æ¨™: {metric_text} ({len(enriched['metric_description'])}æ–‡å­—ã®èª¬æ˜)")
                else:
                    print(f"  âœ… è©•ä¾¡æŒ‡æ¨™: {metric_text}")
            if enriched.get("data_types"):
                print(f"  âœ… ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {', '.join(enriched['data_types'])}")
            if enriched.get("tags"):
                print(f"  âœ… ã‚¿ã‚°: {', '.join(enriched['tags'][:5])}" +
                      (f" (+{len(enriched['tags'])-5}å€‹)" if len(enriched['tags']) > 5 else ""))
            if enriched.get("domain"):
                print(f"  âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³: {enriched['domain']}")
            if enriched.get("dataset_info"):
                dataset_info = json.loads(enriched['dataset_info'])
                files_count = len(dataset_info.get('files', []))
                features_count = len(dataset_info.get('features', []))
                print(f"  âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±: {files_count}ãƒ•ã‚¡ã‚¤ãƒ«, {features_count}ç‰¹å¾´é‡")

            # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
            if not args.dry_run:
                if update_competition(enriched):
                    print(f"  ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°æˆåŠŸ")
                    success_count += 1
                else:
                    print(f"  âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°å¤±æ•—")
                    error_count += 1
            else:
                print(f"  ğŸ” [DRY RUN] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã¯ã‚¹ã‚­ãƒƒãƒ—")
                success_count += 1

        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            error_count += 1
            continue

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("å‡¦ç†å®Œäº†")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {success_count}ä»¶")
    if error_count > 0:
        print(f"âŒ å¤±æ•—: {error_count}ä»¶")
    if args.dry_run:
        print("ğŸ” DRY RUN ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“")


if __name__ == "__main__":
    main()
