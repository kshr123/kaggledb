#!/usr/bin/env python3
"""
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

2-3ä»¶ã®ã‚³ãƒ³ãƒšã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import argparse

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '02_backend'))

from app.services.scraper_service import ScraperService


def main():
    parser = argparse.ArgumentParser(description="ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    parser.add_argument(
        "--show-browser",
        action="store_true",
        help="ãƒ–ãƒ©ã‚¦ã‚¶ã‚’è¡¨ç¤ºã—ã¦å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼‰"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=3,
        help="ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚³ãƒ³ãƒšæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰"
    )
    parser.add_argument(
        "--cache-ttl",
        type=int,
        default=1,
        help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆæ—¥æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰"
    )

    args = parser.parse_args()

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ headless=True, --show-browser ã§ False ã«
    headless = not args.show_browser

    print("=" * 60)
    print("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print(f"ãƒ¢ãƒ¼ãƒ‰: {'ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹' if headless else 'ãƒ–ãƒ©ã‚¦ã‚¶è¡¨ç¤º'}")
    print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥TTL: {args.cache_ttl}æ—¥")

    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³
    all_competitions = [
        'titanic',           # å®šç•ªãƒ»å®‰å®š
        'house-prices',      # å®šç•ªãƒ»å®‰å®š
        'digit-recognizer',  # å®šç•ªãƒ»å®‰å®š
    ]
    test_competitions = all_competitions[:args.limit]

    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹å–å¾—
    if not headless:
        print("\nâš ï¸  ãƒ–ãƒ©ã‚¦ã‚¶ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒè¡¨ç¤ºã•ã‚Œã¾ã™...")

    scraper = ScraperService(cache_ttl_days=args.cache_ttl, headless=headless)

    print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {len(test_competitions)}ä»¶")
    print("-" * 60)

    # å„ã‚³ãƒ³ãƒšã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    for i, comp_id in enumerate(test_competitions, 1):
        print(f"\n{'='*60}")
        print(f"[{i}/{len(test_competitions)}] {comp_id}")
        print('='*60)

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        result = scraper.get_competition_details(comp_id)

        if result:
            print(f"\nâœ… æˆåŠŸï¼")
            print(f"\nå–å¾—ã—ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:")
            for key, value in result.items():
                if key == 'scraped_at':
                    print(f"  - {key}: {value}")
                elif isinstance(value, str):
                    # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯æœ€åˆã®200æ–‡å­—ã®ã¿è¡¨ç¤º
                    preview = value[:200] + '...' if len(value) > 200 else value
                    print(f"  - {key}: {preview}")
                else:
                    print(f"  - {key}: {value}")

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆï¼ˆ2å›ç›®ã¯å³åº§ã«è¿”ã‚‹ï¼‰
            print(f"\nğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆï¼ˆ2å›ç›®ã®å–å¾—ï¼‰")
            result2 = scraper.get_competition_details(comp_id)
            if result2:
                print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—æˆåŠŸï¼")
        else:
            print(f"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—")

        print("-" * 60)

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 60)
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª")
    print("  2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’LLMã§å‡¦ç†ã—ã¦è¦ç´„ç”Ÿæˆ")
    print("  3. enrich_competitions.py ã‚’æ›´æ–°ã—ã¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾å¿œ")


if __name__ == "__main__":
    main()
